import json
import zipfile
from abc import abstractmethod
from functools import partial
from io import BytesIO

import equinox as eqx
import jax.numpy as jnp
import requests
from cnpe.models import AbstractNumpyroGuide, AbstractNumpyroModel
from cnpe.numpyro_utils import (
    shape_only_trace,
    validate_data_and_model_match,
)
from jaxtyping import Array, PRNGKeyArray
from numpyro.util import check_model_guide_match


class AbstractTask(eqx.Module):
    """A model, guide and method for generating ground truth samples."""

    model: eqx.AbstractVar[AbstractNumpyroModel]
    guide: eqx.AbstractVar[AbstractNumpyroGuide]
    name: eqx.AbstractClassVar[str]

    def __check_init__(self):
        model = self.model.reparam()
        model_trace = shape_only_trace(model)
        obs = {}
        for name in model.observed_names:
            if name not in model_trace:
                raise ValueError(
                    f"Trace of model does not include observed node {name}.",
                )
            obs[name] = jnp.empty(
                shape=model_trace[name]["value"].shape,
                dtype=model_trace[name]["value"].dtype,
            )  # keep runtime type checker happy

        check_model_guide_match(
            model_trace=shape_only_trace(model, obs=obs),
            guide_trace=shape_only_trace(self.guide, obs=obs),
        )

    @abstractmethod
    def get_latents_and_observed(
        self,
        key: PRNGKeyArray,
    ) -> tuple[dict[str, Array], dict[str, Array]]:
        """Get the observations and parameters.

        The parameters are from a reference posterior if available, otherwise, they are
        the ground truth parameters used to generate the observation.
        """

    @abstractmethod
    def validate_data(self, latents: dict[str, Array], obs: dict[str, Array]):
        """Checks the data produced by get_latents_and_observed is what is expected.

        Specifically, checks the shapes and names are correct, and that a batch
        dimension in the latents is present for tasks with a reference posterior.
        """
        pass

    def get_latents_and_observed_and_validate(self, key: PRNGKeyArray):
        """Get data and checks matches model trace and model.observed_names."""
        latents, obs = self.get_latents_and_observed(key)
        self.validate_data(latents, obs)

        data = {"latents": latents, "observed": obs}
        for key, dat in data.items():
            for name, arr in dat.items():
                dat[name] = eqx.error_if(
                    x=arr,
                    pred=~jnp.isfinite(arr),
                    msg=f"{name} in {key} had non-finite values",
                )
        return data["latents"], data["observed"]


class AbstractTaskWithoutReference(AbstractTask):
    """A task without a reference posterior.

    The observation and parameters are generated by sampling the model.
    """

    def get_latents_and_observed(self, key: PRNGKeyArray):
        """Generate an observation and ground truth latents from the model."""
        return self.model.reparam(set_val=False).sample_joint(key)

    def validate_data(self, latents: dict[str, Array], obs: dict[str, Array]):
        model = self.model.reparam(set_val=False)
        for data, names in [(latents, model.latent_names), (obs, model.observed_names)]:
            validate_data_and_model_match(data, model=model, assert_present=names)


class AbstractTaskWithReference(AbstractTask):
    """A task with a corresponding reference posterior."""

    def validate_data(self, latents: dict[str, Array], obs: dict[str, Array]):
        """Checks that there exists a single batch dimension in latents."""
        model = self.model.reparam(set_val=False)
        validate_data_and_model_match(obs, model, assert_present=model.observed_names)
        validate_latents_fn = partial(
            validate_data_and_model_match,
            model=model,
            assert_present=model.latent_names,
        )
        eqx.filter_vmap(validate_latents_fn)(latents)


# TODO Consider using associated python package
def get_posterior_db_reference_posterior(name) -> dict:
    """Get the reference posterior draws from posteriordb.

    https://github.com/stan-dev/posteriordb

    Args:
        name: The name of the zip file containing the draws, exluding the extension.
    """
    # Targetting tagged release 0.5.0 for better reproducibility
    url = f"https://github.com/stan-dev/posteriordb/raw/0.5.0/posterior_database/reference_posteriors/draws/draws/{name}.json.zip"

    # Send a GET request to the URL
    response = requests.get(url)
    response.raise_for_status()
    zip_content = BytesIO(response.content)

    # Extract the zip file
    with zipfile.ZipFile(zip_content, "r") as zip_ref:
        assert len(zip_ref.infolist()) == 1
        zip_info = zip_ref.infolist()[0]

        # Extract the JSON file from the zip
        with zip_ref.open(zip_info) as json_file:
            # Read the JSON data
            draws = json.load(json_file)

    # Concatenate the chains
    draws = {
        k: jnp.concatenate([jnp.asarray(chain[k]) for chain in draws])
        for k in draws[0].keys()
    }

    # Names may be of form param[1] param[2]. We want to stack these into an array
    stacked_draws = {k.split("[")[0]: [] for k in draws.keys()}
    for k, v in draws.items():
        key_root = k.split("[")[0]
        stacked_draws[key_root].append(v)

    return {k: jnp.stack(v, axis=-1).squeeze() for k, v in stacked_draws.items()}
