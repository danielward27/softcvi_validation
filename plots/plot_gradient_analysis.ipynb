{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Analysis of the gradient for different $p^-(\\theta)$"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Imports"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "import math\n",
                "import os\n",
                "from collections.abc import Callable\n",
                "from functools import partial\n",
                "\n",
                "import equinox as eqx\n",
                "import jax\n",
                "import jax.numpy as jnp\n",
                "import jax.random as jr\n",
                "import matplotlib.pyplot as plt\n",
                "from flowjax.distributions import Normal\n",
                "from flowjax.experimental.numpyro import sample\n",
                "from jaxtyping import Array, ArrayLike, Scalar\n",
                "from pyrox.program import AbstractProgram\n",
                "\n",
                "from softcvi_validation import utils\n",
                "\n",
                "os.chdir(utils.get_abspath_project_root())\n",
                "\n",
                "from scripts.run_task import get_losses  # noqa: E402\n",
                "\n",
                "plt.style.use(\"./plots/style.mplstyle\")\n",
                "palette = utils.get_palette()\n",
                "negative_distribution = \"proposal\"\n",
                "n_particles = 8"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Define the model\n",
                "We use a toy Gaussian example, matching that from [Glockler, Deistler and Macke, 2022](https://arxiv.org/abs/2203.04176), except we also can scale the dimensionality.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ToyGaussian(AbstractProgram):\n",
                "    dim: int\n",
                "    true_loc = 4/5\n",
                "    true_log_scale = math.log(jnp.sqrt(4/5))\n",
                "\n",
                "    def __init__( self, *, dim: int):\n",
                "        self.dim = dim\n",
                "\n",
                "    def __call__(self, obs: Array = None):\n",
                "        theta = sample(\"theta\", Normal(jnp.zeros(self.dim), 2))\n",
                "        sample(\"x\", Normal(theta, 1), obs=obs)\n",
                "\n",
                "\n",
                "class ToyGaussianGuide(AbstractProgram):\n",
                "    \"\"\"Toy Gaussian guide, parameterized using loc and log_scale. \n",
                "\n",
                "    Args:\n",
                "        loc: Mean parameter.\n",
                "        log_scale: Log standard deviation.\n",
                "    \"\"\"\n",
                "    normal: Normal\n",
                "\n",
                "    def __init__(\n",
                "        self,\n",
                "        loc: ArrayLike,\n",
                "        log_scale: ArrayLike,\n",
                "        ):\n",
                "        self.normal = Normal(loc, jnp.exp(log_scale))\n",
                "        \n",
                "    def __call__(self, obs=None):\n",
                "        sample(\"theta\", self.normal)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_grads(dim, get_guide: Callable, params: Array, n_keys: int, loss_fns: dict):\n",
                "    model = ToyGaussian(dim=dim)\n",
                "    obs = jnp.ones((dim, ))\n",
                "    \n",
                "    grads = {}\n",
                "\n",
                "    def _get_grad_fn(loss, params):\n",
                "        \n",
                "        @jax.jit\n",
                "        @partial(jax.vmap, in_axes=[0, None]) # Single seed, several params\n",
                "        @jax.grad\n",
                "        def _grad(params, key):  # Single seed, single param\n",
                "            guide = get_guide(params)\n",
                "            return loss(\n",
                "                *eqx.partition((model, guide), eqx.is_inexact_array),\n",
                "                key=key,\n",
                "                obs=obs,\n",
                "                )\n",
                "        \n",
                "        params = jnp.broadcast_to(params[:, None], (params.size, dim))\n",
                "        # We use map over keys (less memory hungry than vmap)\n",
                "        return lambda k: jax.lax.map(partial(_grad, params), k)\n",
                "\n",
                "    for k, loss in loss_fns.items():\n",
                "        grad_fn = _get_grad_fn(loss=loss, params=params)\n",
                "        keys = jr.split(jr.key(1), n_keys)\n",
                "        grads[k] = grad_fn(keys) # (n_keys, n_params, dim)\n",
                "    return grads\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "ename": "TypeError",
                    "evalue": "Can't instantiate abstract class ToyGaussian without an implementation for abstract method '__call__'",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[7], line 90\u001b[0m\n\u001b[1;32m     86\u001b[0m         ax\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$d=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m params \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mlinspace(ToyGaussian\u001b[38;5;241m.\u001b[39mtrue_loc\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m, ToyGaussian\u001b[38;5;241m.\u001b[39mtrue_loc\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m200\u001b[39m)\n\u001b[0;32m---> 90\u001b[0m plot_snr_on_ax(    \n\u001b[1;32m     91\u001b[0m     get_guide_fn\u001b[38;5;241m=\u001b[39mmu_to_guide,\n\u001b[1;32m     92\u001b[0m     loss_fns\u001b[38;5;241m=\u001b[39mloss_fns,\n\u001b[1;32m     93\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m     94\u001b[0m     truth\u001b[38;5;241m=\u001b[39mToyGaussian\u001b[38;5;241m.\u001b[39mtrue_loc,\n\u001b[1;32m     95\u001b[0m     axes\u001b[38;5;241m=\u001b[39maxes[:, :\u001b[38;5;28mlen\u001b[39m(DIMS)],\n\u001b[1;32m     96\u001b[0m     )\n\u001b[1;32m     98\u001b[0m params \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mlinspace(ToyGaussian\u001b[38;5;241m.\u001b[39mtrue_log_scale\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m, ToyGaussian\u001b[38;5;241m.\u001b[39mtrue_log_scale\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m     99\u001b[0m plot_snr_on_ax(\n\u001b[1;32m    100\u001b[0m     get_guide_fn\u001b[38;5;241m=\u001b[39mlog_scale_to_guide,\n\u001b[1;32m    101\u001b[0m     loss_fns\u001b[38;5;241m=\u001b[39mloss_fns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m     axes\u001b[38;5;241m=\u001b[39maxes[:, \u001b[38;5;28mlen\u001b[39m(DIMS):],\n\u001b[1;32m    105\u001b[0m )\n",
                        "Cell \u001b[0;32mIn[7], line 34\u001b[0m, in \u001b[0;36mplot_snr_on_ax\u001b[0;34m(get_guide_fn, loss_fns, params, truth, axes)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_snr_on_ax\u001b[39m(\n\u001b[1;32m     27\u001b[0m     get_guide_fn,\n\u001b[1;32m     28\u001b[0m     loss_fns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     axes,\n\u001b[1;32m     32\u001b[0m ):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, dim \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(DIMS):\n\u001b[0;32m---> 34\u001b[0m         grads \u001b[38;5;241m=\u001b[39m get_grads(dim, get_guide_fn, params, loss_fns\u001b[38;5;241m=\u001b[39mloss_fns, n_keys\u001b[38;5;241m=\u001b[39mn_keys)\n\u001b[1;32m     36\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m grads\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     37\u001b[0m             \u001b[38;5;66;03m# Following https://arxiv.org/abs/1802.04537, we compute independently\u001b[39;00m\n\u001b[1;32m     38\u001b[0m             \u001b[38;5;66;03m# for each dim and then we reduce using the mean.\u001b[39;00m\n\u001b[1;32m     39\u001b[0m             label \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma=\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m$\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124malpha$=\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "Cell \u001b[0;32mIn[6], line 2\u001b[0m, in \u001b[0;36mget_grads\u001b[0;34m(dim, get_guide, params, n_keys, loss_fns)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_grads\u001b[39m(dim, get_guide: Callable, params: Array, n_keys: \u001b[38;5;28mint\u001b[39m, loss_fns: \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     model \u001b[38;5;241m=\u001b[39m ToyGaussian(dim\u001b[38;5;241m=\u001b[39mdim)\n\u001b[1;32m      3\u001b[0m     obs \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mones((dim, ))\n\u001b[1;32m      5\u001b[0m     grads \u001b[38;5;241m=\u001b[39m {}\n",
                        "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
                        "File \u001b[0;32m~/miniconda3/envs/softcvi_env/lib/python3.12/site-packages/equinox/_better_abstract.py:227\u001b[0m, in \u001b[0;36mABCMeta.__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     abstract_class_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__abstractclassvars__)  \u001b[38;5;66;03m# pyright: ignore\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt instantiate abstract class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with abstract class \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattributes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mabstract_class_vars\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    226\u001b[0m     )\n\u001b[0;32m--> 227\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__abstractvars__) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# pyright: ignore\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     abstract_class_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__abstractvars__)  \u001b[38;5;66;03m# pyright: ignore\u001b[39;00m\n",
                        "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class ToyGaussian without an implementation for abstract method '__call__'"
                    ]
                },
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 550x400 with 12 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "def mu_to_guide(mu):\n",
                "    return ToyGaussianGuide(mu, ToyGaussian.true_log_scale)\n",
                "\n",
                "def log_scale_to_guide(log_scale):\n",
                "    return ToyGaussianGuide(ToyGaussian.true_loc, log_scale)\n",
                "\n",
                "n_keys = 5000\n",
                "DIMS = [1, 50]\n",
                "\n",
                "total_fig = plt.figure(\n",
                "        figsize=(plt.rcParams[\"figure.figsize\"][0], 4),\n",
                "        layout=\"constrained\",\n",
                "        )\n",
                "\n",
                "fig, legend_fig = total_fig.subfigures(nrows=2, height_ratios=[20,1])\n",
                "axes = fig.subplots(ncols=2*len(DIMS), nrows=3, sharex=\"col\")\n",
                "\n",
                "\n",
                "loss_fns = get_losses(\n",
                "    n_particles=n_particles,\n",
                "    negative_distribution=negative_distribution,\n",
                "    )\n",
                "loss_fns.pop(\"ELBO\")\n",
                "\n",
                "\n",
                "def plot_snr_on_ax(\n",
                "    get_guide_fn,\n",
                "    loss_fns,\n",
                "    params,\n",
                "    truth,\n",
                "    axes,\n",
                "):\n",
                "    for i, dim in enumerate(DIMS):\n",
                "        grads = get_grads(dim, get_guide_fn, params, loss_fns=loss_fns, n_keys=n_keys)\n",
                "        \n",
                "        for k, v in grads.items():\n",
                "            # Following https://arxiv.org/abs/1802.04537, we compute independently\n",
                "            # for each dim and then we reduce using the mean.\n",
                "            label = k.replace(\"a=\", r\"$\\alpha$=\")\n",
                "            s = 2\n",
                "\n",
                "            if negative_distribution == \"proposal\" and k==\"SNIS-fKL\":\n",
                "                linestyle = (0, (3, 1))\n",
                "            else:\n",
                "                linestyle = \"-\"\n",
                "\n",
                "            # Signal\n",
                "            signal = jnp.abs(jnp.mean(v, axis=0)).mean(axis=-1)\n",
                "\n",
                "            axes[0, i].plot(\n",
                "                params,\n",
                "                signal,\n",
                "                label=label,\n",
                "                color=palette[k],\n",
                "                linewidth=s,\n",
                "                linestyle=linestyle,\n",
                "                alpha=0.6,\n",
                "            )\n",
                "\n",
                "            # Noise\n",
                "            noise = jnp.std(v, axis=0).mean(axis=-1)\n",
                "\n",
                "            axes[1, i].plot(\n",
                "                params,\n",
                "                noise,\n",
                "                label=label,\n",
                "                color=palette[k],\n",
                "                linewidth=s,\n",
                "                alpha=0.6,\n",
                "            )\n",
                "\n",
                "            # SNR\n",
                "            axes[2, i].plot(\n",
                "                params,\n",
                "                signal / noise,\n",
                "                label=label,\n",
                "                color=palette[k],\n",
                "                linewidth=s,\n",
                "                alpha=0.6,\n",
                "            )\n",
                "\n",
                "    for ax in axes.ravel():\n",
                "        ax.axvline(x=truth, color=\"black\", linestyle=\"dashed\", lw=0.75)\n",
                "\n",
                "    for ax, dim in zip(axes[0], DIMS, strict=True):\n",
                "        ax.set_title(rf\"$d={dim}$\")\n",
                "\n",
                "\n",
                "params = jnp.linspace(ToyGaussian.true_loc-3, ToyGaussian.true_loc+3, 200)\n",
                "plot_snr_on_ax(    \n",
                "    get_guide_fn=mu_to_guide,\n",
                "    loss_fns=loss_fns,\n",
                "    params=params,\n",
                "    truth=ToyGaussian.true_loc,\n",
                "    axes=axes[:, :len(DIMS)],\n",
                "    )\n",
                "\n",
                "params = jnp.linspace(ToyGaussian.true_log_scale-3, ToyGaussian.true_log_scale+3, 200)\n",
                "plot_snr_on_ax(\n",
                "    get_guide_fn=log_scale_to_guide,\n",
                "    loss_fns=loss_fns,\n",
                "    params=params,\n",
                "    truth=ToyGaussian.true_log_scale,\n",
                "    axes=axes[:, len(DIMS):],\n",
                ")\n",
                "\n",
                "x_labels = [\n",
                "     r\"$\\mu$\",\n",
                "     r\"$\\boldsymbol{\\mu}$\",\n",
                "     r\"$\\log\\sigma$\",\n",
                "     r\"$\\log\\boldsymbol{\\sigma}$\",\n",
                "     ]\n",
                "\n",
                "for ax, xlab in zip(axes[-1], x_labels, strict=True):\n",
                "    ax.set_xlabel(xlab)\n",
                "\n",
                "legend_fig.legend(\n",
                "    *axes[1,0].get_legend_handles_labels(),\n",
                "    ncols=5,\n",
                "    )\n",
                "\n",
                "[ax.set_box_aspect(1) for ax in axes.ravel()]\n",
                "\n",
                "# Set titles and labels:\n",
                "axes[0, 0].set_ylabel(\"Signal\")\n",
                "axes[1, 0].set_ylabel(\"Noise\")\n",
                "axes[2, 0].set_ylabel(\"SNR\")\n",
                "\n",
                "total_fig.savefig(\n",
                "    f\"plots/plots/snr_gaussian_k={n_particles}_negative={negative_distribution}.pdf\",\n",
                "    )\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "softcvi_env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
